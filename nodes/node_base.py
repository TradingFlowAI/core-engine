import abc
import asyncio
import json
import logging
import traceback
from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING, Any, Dict, List, Optional

import httpx

from infra.config import CONFIG
from infra.exceptions.tf_exception import (
    InsufficientCreditsException,
    NodeStopExecutionException,
)
from infra.mq.node_signal_consumer import NodeSignalConsumer
from infra.mq.node_signal_publisher import NodeSignalPublisher
from common.edge import Edge
from common.signal_types import Signal, SignalType
from common.state_store import StateStoreFactory
from core.redis_signal_publisher_async import publish_signal_async
from core.signal_persistence import persist_signal

if TYPE_CHECKING:
    from common.state_store import StateStore


@dataclass
class InputHandle:
    """Input handle definition"""

    name: str
    data_type: type
    description: str = ""
    example: Any = None
    auto_update_attr: str = None
    is_aggregate: bool = False

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary format"""
        return {
            "type": self.data_type.__name__,
            "description": self.description,
            "example": self.example,
            "auto_update_attr": self.auto_update_attr,
            "is_aggregate": self.is_aggregate,
        }


@dataclass
class OutputHandle:
    """Output handle definition"""

    name: str
    data_type: type
    description: str = ""
    example: Any = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary format"""
        return {
            "name": self.name,
            "type": self.data_type.__name__,
            "description": self.description,
            "example": self.example,
        }


@dataclass
class NodeMetadata:
    """Node metadata definition"""

    version: str = "0.0.1"
    display_name: str = ""
    node_category: str = "base"  # "base", "instance", "variant"
    base_node_type: Optional[str] = None
    description: str = ""
    author: str = ""
    tags: List[str] = None

    def __post_init__(self):
        if self.tags is None:
            self.tags = []

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary format"""
        return {
            "version": self.version,
            "display_name": self.display_name,
            "node_category": self.node_category,
            "base_node_type": self.base_node_type,
            "description": self.description,
            "author": self.author,
            "tags": self.tags,
        }


class NodeStatus(Enum):
    """Node status enumeration"""

    PENDING = "pending"  # Waiting to execute
    RUNNING = "running"  # Currently executing
    COMPLETED = "completed"  # Execution completed
    FAILED = "failed"  # Execution failed
    SKIPPED = "skipped"  # Execution skipped
    TERMINATED = "terminated"  # Execution terminated
    AWAITING_INPUT = "awaiting_input"  # Waiting for user interaction (Interactive Node)


class NodeBase(abc.ABC):
    """Base node class"""

    # Class-level metadata - can be overridden by subclasses
    _metadata: Optional[NodeMetadata] = None

    def __init__(
        self,
        flow_id: str,
        component_id: int,
        cycle: int,
        node_id: str,
        name: str,
        input_edges: List[Edge] = None,
        output_edges: List[Edge] = None,
        state_store: "StateStore" = None,
        node_type: str = None,  # èŠ‚ç‚¹ç±»å‹ï¼Œç”¨äºæ—¥å¿—å’ŒçŠ¶æ€å‘å¸ƒ
        # æ·»åŠ å…ƒæ•°æ®ç›¸å…³å‚æ•°
        version: str = None,
        display_name: str = None,
        node_category: str = None,
        base_node_type: str = None,
        description: str = None,
        author: str = None,
        tags: List[str] = None,
        # Credits ç›¸å…³å‚æ•°
        user_id: str = None,
        enable_credits: bool = True,
        **kwargs  # æ¥æ”¶å…¶ä»–å‚æ•°ï¼Œä¿æŒå‘åå…¼å®¹
    ):
        """
        Initialize node

        Args:
            flow_id: Flow ID
            component_id: Component ID in graph
            cycle: Cycle number
            node_id: Node unique identifier
            name: Node name
            input_edges: List of input edges
            output_edges: List of output edges
            state_store: Initialized state store instance (used if provided)
            node_type: Node type identifier (e.g., 'vault_node', 'buy_node')
            version: Node version
            display_name: Display name for UI
            node_category: Node category (base/instance/variant)
            base_node_type: Base node type if this is an instance
            description: Node description
            author: Node author
            tags: Node tags
            user_id: User ID for credits tracking
            enable_credits: Whether to enable credits tracking (default: True)
        """
        # Logger setup
        self.logger = logging.getLogger(f"Node.{node_id}")
        self.flow_id = flow_id
        self.component_id = component_id
        self.cycle = cycle
        self.node_id = node_id
        self.name = name
        self.node_type = node_type or self.__class__.__name__.lower().replace('node', '_node')  # ä¿å­˜èŠ‚ç‚¹ç±»å‹
        self._input_edges = input_edges or []
        self._output_edges = output_edges or []

        # Credits tracking
        self.user_id = user_id
        self.enable_credits = enable_credits

        # åˆå§‹åŒ–å…ƒæ•°æ®
        self._instance_metadata = NodeMetadata(
            version=version or "0.0.1",
            display_name=display_name or name or self.__class__.__name__,
            node_category=node_category or "base",
            base_node_type=base_node_type,
            description=description or self.__class__.__doc__ or "",
            author=author or "",
            tags=tags or []
        )
        # NOTE: æè¿°è¿è¡Œæ—¶çš„è¾“å…¥ä¿¡å·æœ‰å“ªäº›ï¼Œæ³¨æ„ä¸_input_handlesçš„åŒºåˆ«
        self._input_signals = {}

        # Input handles registry
        # NOTE: æè¿°é™æ€çš„handleæœ‰å“ªäº›
        self._input_handles: Dict[str, InputHandle] = {}
        
        # Output handles registry
        self._output_handles: Dict[str, OutputHandle] = {}

        # Register input and output handles defined by subclass
        self._register_input_handles()
        self._register_output_handles()

        self.status = NodeStatus.PENDING
        self.error_message = None
        
        # å­˜å‚¨æœ€åå‘é€çš„è¾“å‡ºæ•°æ®ï¼Œç”¨äºåœ¨èŠ‚ç‚¹å®Œæˆæ—¶é€šè¿‡ WebSocket æ¨é€ç»™å‰ç«¯
        self._last_output_data: Dict[str, Any] = {}

        # Message queue configuration
        if self._input_edges:
            self.logger.debug(
                "Node %s has input %d edges: %s",
                self.node_id,
                len(self._input_edges),
                self._input_edges,
            )
            self.node_signal_consumer = NodeSignalConsumer(
                self.flow_id,
                self.component_id,
                self.cycle,
                self.node_id,
                self._input_edges,
                on_signal_handler=self._on_signal_received,
            )
            for edge in self._input_edges:
                if edge.target_node == self.node_id:
                    edge_key = self._get_edge_key(
                        edge.source_node,
                        edge.source_node_handle,
                        edge.target_node_handle,
                    )
                    self._input_signals[edge_key] = None
            self.logger.debug(
                "Node %s registered input signals: %s",
                self.node_id,
                list(self._input_signals.keys()),
            )
        else:
            self.logger.debug("Node %s has no input edges", self.node_id)
            self.node_signal_consumer = None
        self.node_signal_publisher = NodeSignalPublisher(
            self.flow_id,
            self.component_id,
            self.cycle,
            self.node_id,
            self._output_edges,
        )

        # State store configuration
        self.state_store = state_store  # Use provided state_store
        self._owns_state_store = False  # Flag if we created the state_store

        # Signal ready future - used to notify when all required signals are received
        self._signal_ready_future = None

        # æ·»åŠ åœæ­¢æ‰§è¡Œæ ‡è®°
        self._stop_execution_requested = False
        self._stop_execution_reason = None
        self._stop_execution_source = None

        # Initialize flow execution log service
        self._log_service = None

    async def _initialize_log_service(self):
        """Initialize flow execution log service lazily"""
        if self._log_service is None:
            try:
                from infra.db.services.flow_execution_log_service import (
                    FlowExecutionLogService,
                )
                self._log_service = FlowExecutionLogService()
            except Exception as e:
                self.logger.warning("Failed to initialize log service: %s", str(e))

    async def persist_log(
        self,
        message: str,
        log_level: str = "INFO",
        log_source: str = "node",
        log_metadata: Optional[Dict] = None,
    ):
        """
        Persist log message to database, Redis, and console

        Args:
            message: Log message content
            log_level: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
            log_source: Log source (node, system, user)
            log_metadata: Additional structured metadata
        """
        # Log to console first
        log_level_upper = log_level.upper()
        if log_level_upper == "DEBUG":
            self.logger.debug(message)
        elif log_level_upper == "INFO":
            self.logger.info(message)
        elif log_level_upper == "WARNING":
            self.logger.warning(message)
        elif log_level_upper == "ERROR":
            self.logger.error(message)
        elif log_level_upper == "CRITICAL":
            self.logger.critical(message)
        else:
            self.logger.info(message)

        # Persist to database
        try:
            await self._initialize_log_service()
            if self._log_service:
                await self._log_service.create_log(
                    flow_id=self.flow_id,
                    cycle=self.cycle,
                    message=message,
                    node_id=self.node_id,
                    log_level=log_level_upper,
                    log_source=log_source,
                    log_metadata=log_metadata,
                )
        except Exception as e:
            # Don't let logging errors break node execution
            self.logger.warning("Failed to persist log to database: %s", str(e))

        # Publish to Redis for real-time streaming (async, with retry)
        try:
            from core.redis_log_publisher_async import publish_log_async
            from datetime import datetime

            log_entry = {
                "node_id": self.node_id,
                "node_type": self.node_type,
                "level": log_level_upper.lower(),
                "message": message,
                "log_source": log_source,
            }

            # Add metadata if provided
            if log_metadata:
                log_entry["metadata"] = log_metadata

            # Publish to Redis asynchronously (with automatic retry)
            await publish_log_async(self.flow_id, self.cycle, log_entry, max_retries=3)

        except Exception as e:
            # Don't fail if Redis publish fails - just log the error
            self.logger.debug("Failed to publish log to Redis: %s", str(e))

    async def initialize_state_store(self) -> bool:
        """
        Initialize state store

        Returns:
            bool: Whether initialization was successful
        """
        # If state_store already exists, use it
        if self.state_store is not None:
            self.logger.info("Using provided state store for node %s", self.node_id)

            # Set initial node status
            await self.set_status(NodeStatus.PENDING)

            # Clear any termination flag that might exist
            await self.state_store.clear_termination_flag(self.node_id)

            return True

        # Otherwise create a new state_store instance
        try:
            # Create state store using factory pattern
            self.state_store = StateStoreFactory.create()
            self._owns_state_store = True  # Mark as self-created

            # Initialize state store
            if not await self.state_store.initialize():
                return False

            # Set initial node status
            await self.set_status(NodeStatus.PENDING)

            # Clear any termination flag that might exist
            await self.state_store.clear_termination_flag(self.node_id)

            self.logger.info("State store initialized for node %s", self.node_id)
            return True
        except Exception as e:
            self.logger.error("Failed to initialize state store: %s", str(e))
            return False

    async def close_state_store(self):
        """Close state store connection, only if we created it"""
        if self.state_store and self._owns_state_store:  # Only close if we created it
            await self.state_store.close()
            self.logger.info("State store connection closed for node %s", self.node_id)

    async def initialize_message_queue(self) -> bool:
        """
        Initialize message queue asynchronously

        Returns:
            bool: Whether initialization was successful
        """
        try:
            await self.node_signal_publisher.connect()

            # Register consumer if there are signals to listen for
            if self._input_edges:
                await self.node_signal_consumer.connect()

            self.logger.info("Message queue initialized for node %s", self.node_id)
            return True

        except Exception as e:
            self.logger.error("Failed to initialize message queue: %s", str(e))
            self.logger.error(traceback.format_exc())
            return False

    def _deduce_input_handler_name(self, handle_name: str) -> str:
        """
        Get standardized handler function name for a given handle

        Args:
            handle_name: The input handle name

        Returns:
            str: The standardized handler function name
        """
        return f"_on_{handle_name}_received"

    def _get_edge_key(
        self, source_node: str, source_handle: str, target_handle: str
    ) -> str:
        """
        Generate edge key for input signals tracking

        Args:
            source_node: Source node ID
            source_handle: Source handle name
            target_handle: Target handle name

        Returns:
            str: Edge key in format "source_node:source_handle->target_handle"
        """
        return f"{source_node}:{source_handle}->{target_handle}"

    def _find_edge_by_handle(self, handle: str) -> Edge:
        """
        Find edge by target handle name

        Args:
            handle: Target handle name

        Returns:
            Edge: First matching edge, or None if not found
        """
        for edge in self._input_edges:
            if edge.target_node_handle == handle:
                return edge
        return None

    async def _on_signal_received(
        self, signal: Signal, handle: str = None, signal_context: Dict[str, Any] = None
    ) -> None:
        """
        Process received signal

        1. Add signal to the signal queue
        2. Check if all required signals have been received
        3. Trigger future if signal_ready_future is set and execution conditions are met

        Args:
            signal: Received signal
            handle: Target handle name
            signal_context: Signal context containing routing key information
        """
        try:
            self.logger.info(
                "Received signal: %s , handle: %s", signal.type.value, handle
            )
            # å¤„ç†åœæ­¢æ‰§è¡Œä¿¡å·
            if handle == "STOP_EXECUTION" or signal.type == SignalType.STOP_EXECUTION:
                await self._handle_stop_execution_signal(signal)
                return

            # Add to signal dictionary
            if handle in [edge.target_node_handle for edge in self._input_edges]:
                # æ‰¾åˆ°å¯¹åº”çš„edgeæ¥æ„å»ºå®Œæ•´çš„key
                self.logger.debug("Received signal[signal.payload] %s", signal.payload)

                # ä¼˜å…ˆä» signal_context ä¸­è·å– source ä¿¡æ¯
                source_node = None
                source_handle = None

                if signal_context and signal_context.get("parsed", False):
                    # ä» routing key è§£æçš„ä¸Šä¸‹æ–‡ä¸­è·å–
                    source_node = signal_context.get("source_node")
                    source_handle = signal_context.get("source_handle")
                    self.logger.debug(
                        "Found source info from signal_context: node=%s, handle=%s",
                        source_node,
                        source_handle,
                    )
                else:
                    # å›é€€åˆ°ä» signal.payload ä¸­è·å–ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
                    if signal.payload and isinstance(signal.payload, dict):
                        source_node = signal.payload.get("_source_node")
                        source_handle = signal.payload.get("_source_handle")
                        self.logger.debug(
                            "Found source info from signal.payload: node=%s, handle=%s",
                            source_node,
                            source_handle,
                        )

                if source_node and source_handle:
                    edge_key = self._get_edge_key(source_node, source_handle, handle)
                    if edge_key in self._input_signals:
                        # Update signal
                        self._input_signals[edge_key] = signal
                        self.logger.debug("Updated signal for edge: %s", edge_key)

                        # Attach source_handle to signal object for aggregation logic
                        signal.source_handle = source_handle
                        signal.source_node = source_node

                        # Persist received signal data to database for comprehensive status API
                        signal_data = {
                            handle: {
                                'signal_type': signal.type.value if hasattr(signal.type, 'value') else str(signal.type),
                                'payload': signal.payload or {},
                                'timestamp': signal.timestamp,
                                'source_node': source_node,
                                'source_handle': source_handle
                            }
                        }

                        await self.persist_log(
                            message=f"Signal received at {handle} from {source_node}:{source_handle}",
                            log_level="INFO",
                            log_source="node",
                            log_metadata={
                                # ç®€åŒ–å…ƒæ•°æ®ï¼šåªä¿ç•™è·¯ç”±ä¿¡æ¯ï¼Œpayload å­˜åœ¨ Signal è¡¨
                                'event': 'signal_received',
                                'target_handle': handle,
                                'source_node': source_node,
                                'source_handle': source_handle,
                                'signal_type': str(signal.type)
                            }
                        )
                        
                        # ğŸ”¥ å‘å¸ƒ Input Signal åˆ° Redisï¼Œä¾›å‰ç«¯å®æ—¶å±•ç¤º
                        try:
                            # æ¨æ–­æ•°æ®ç±»å‹
                            input_payload = signal.payload
                            input_data_type = "unknown"
                            if input_payload is not None:
                                if isinstance(input_payload, bool):
                                    input_data_type = "boolean"
                                elif isinstance(input_payload, int):
                                    input_data_type = "integer"
                                elif isinstance(input_payload, float):
                                    input_data_type = "float"
                                elif isinstance(input_payload, str):
                                    input_data_type = "string"
                                elif isinstance(input_payload, list):
                                    input_data_type = "array"
                                elif isinstance(input_payload, dict):
                                    input_data_type = "object"
                            
                            await publish_signal_async(
                                flow_id=self.flow_id,
                                cycle=self.cycle,
                                source_node_id=source_node,
                                source_handle=source_handle,
                                target_node_ids=[self.node_id],
                                signal_type=signal.type.value if hasattr(signal.type, 'value') else str(signal.type),
                                payload=input_payload,
                                direction="input",  # æ¥æ”¶çš„ä¿¡å·æ˜¯ input
                                data_type=input_data_type,
                                handle_id=handle,  # ä½¿ç”¨ç›®æ ‡ handle
                            )
                            
                            # ğŸ”¥ æŒä¹…åŒ– Input Signal åˆ°æ•°æ®åº“
                            await persist_signal(
                                flow_id=self.flow_id,
                                cycle=self.cycle,
                                direction="input",
                                from_node_id=source_node,
                                to_node_id=self.node_id,
                                source_handle=source_handle,
                                target_handle=handle,
                                signal_type=signal.type.value if hasattr(signal.type, 'value') else str(signal.type),
                                data_type=input_data_type,
                                payload=input_payload,
                            )
                        except Exception as redis_err:
                            self.logger.warning("Failed to publish/persist input signal: %s", str(redis_err))
                    else:
                        self.logger.warning(
                            "Edge key not found in input signals: %s", edge_key
                        )

                else:
                    # å¦‚æœæ²¡æœ‰sourceä¿¡æ¯ï¼Œå°è¯•ä»edgesä¸­æ¨æ–­ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
                    edge = self._find_edge_by_handle(handle)
                    if edge:
                        edge_key = self._get_edge_key(
                            edge.source_node, edge.source_node_handle, handle
                        )
                        self._input_signals[edge_key] = signal
                        self.logger.debug(
                            f"Updated signal for edge (inferred): {edge_key}"
                        )

                        # Attach source_handle to signal object for aggregation logic (inferred case)
                        signal.source_handle = edge.source_node_handle
                        signal.source_node = edge.source_node

                        # Persist received signal data to database (inferred case)
                        signal_data = {
                            handle: {
                                'signal_type': signal.type.value if hasattr(signal.type, 'value') else str(signal.type),
                                'payload': signal.payload or {},
                                'timestamp': signal.timestamp,
                                'source_node': edge.source_node,
                                'source_handle': edge.source_node_handle
                            }
                        }

                        await self.persist_log(
                            message=f"Signal received at {handle} from {edge.source_node}:{edge.source_node_handle} (inferred)",
                            log_level="INFO",
                            log_source="node",
                            log_metadata={
                                # ç®€åŒ–å…ƒæ•°æ®ï¼šåªä¿ç•™è·¯ç”±ä¿¡æ¯ï¼Œpayload å­˜åœ¨ Signal è¡¨
                                'event': 'signal_received',
                                'target_handle': handle,
                                'source_node': edge.source_node,
                                'source_handle': edge.source_node_handle,
                                'signal_type': str(signal.type),
                                'inferred': True
                            }
                        )
                    else:
                        self.logger.warning(
                            "Cannot determine source for handle %s, no matching edge found",
                            handle,
                        )

                # æ‰§è¡Œé»˜è®¤çš„æˆå‘˜å˜é‡æ›´æ–°é€»è¾‘
                await self._handle_default_signal_processing(handle, signal)

                # ç„¶åæ‰§è¡Œè‡ªå®šä¹‰çš„å¤„ç†å‡½æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                handler_name = self._deduce_input_handler_name(handle)
                if hasattr(self, handler_name):
                    # Call specific signal handler function
                    await getattr(self, handler_name)(signal)

            elif handle == "*":
                # Handle wildcard case, update all input signals
                # æ‹†åŒ…signalï¼Œæ ¹æ®signalä¸­çš„keyæ¥æ›´æ–°æ‰€æœ‰è¾“å…¥ä¿¡å·
                self.logger.info("Received wildcard signal, updating all input signals")
                # Get all available input handles
                input_handles = self.get_input_handles()
                self.logger.debug(
                    "Available input handles: %s", list(input_handles.keys())
                )
                payload = signal.payload
                self.logger.debug("Signal payload: %s", payload)

                # æ£€æŸ¥ payload æ˜¯å¦ä¸ºå­—å…¸ç±»å‹
                if payload and isinstance(payload, dict):
                    # Persist wildcard signal data to database
                    signal_data = {}
                    for handle_name in payload.keys():
                        if handle_name in input_handles:
                            signal_data[handle_name] = {
                                'signal_type': signal.type.value if hasattr(signal.type, 'value') else str(signal.type),
                                'payload': payload[handle_name],
                                'timestamp': signal.timestamp,
                                'wildcard': True
                            }

                    if signal_data:
                        await self.persist_log(
                            message=f"Wildcard signal received with {len(signal_data)} handles",
                            log_level="INFO",
                            log_source="node",
                            log_metadata={
                                # ç®€åŒ–å…ƒæ•°æ®ï¼šåªä¿ç•™æ•°é‡å’Œç±»å‹ï¼Œpayload å­˜åœ¨ Signal è¡¨
                                'event': 'signal_received',
                                'handle_count': len(signal_data),
                                'signal_type': str(signal.type),
                                'wildcard': True
                            }
                        )

                    # Process each handle if it exists in the payload
                    for handle_name, handle_obj in input_handles.items():
                        if handle_name in payload:
                            # å¯¹äºé€šé…ç¬¦æƒ…å†µï¼Œæ›´æ–°æ‰€æœ‰åŒ¹é…è¯¥target_handleçš„edge_key
                            # åˆ›å»ºæ–°çš„Signalå¯¹è±¡ä»¥ä¿æŒç±»å‹ä¸€è‡´æ€§
                            handle_signal = Signal(
                                signal_type=signal.type,
                                payload=payload[handle_name],
                                timestamp=signal.timestamp
                            )
                            for edge_key in self._input_signals.keys():
                                if edge_key.endswith(f"->{handle_name}"):
                                    self._input_signals[edge_key] = handle_signal

                            # æ‰§è¡Œé»˜è®¤çš„æˆå‘˜å˜é‡æ›´æ–°é€»è¾‘
                            await self._handle_default_signal_processing(
                                handle_name, payload[handle_name], is_direct_value=True
                            )

                            # Call the specific handler if it exists
                            handler_name = self._deduce_input_handler_name(handle_name)
                            if hasattr(self, handler_name):
                                self.logger.debug(
                                    "Calling handler %s for handle %s",
                                    handler_name,
                                    handle_name,
                                )
                                # Call the handler with the payload for this handle
                                await getattr(self, handler_name)(payload[handle_name])
                            else:
                                self.logger.debug(
                                    "No handler found for handle %s", handle_name
                                )
                else:
                    self.logger.warning(
                        "Wildcard signal payload is not a dictionary: %s", type(payload)
                    )

            else:
                self.logger.warning("Received signal with unknown handle: %s", handle)

            # Check if all required signals are received, trigger future if set
            if self._signal_ready_future and not self._signal_ready_future.done():
                if self.can_execute():
                    self.logger.debug(
                        "All required signals received, marking ready to execute"
                    )
                    self._signal_ready_future.set_result(True)

        except Exception as e:
            self.logger.error("Error processing signal: %s", str(e))
            raise

    async def _handle_default_signal_processing(
        self, handle_name: str, signal_or_value, is_direct_value: bool = False
    ) -> None:
        """
        å¤„ç†é»˜è®¤çš„ä¿¡å·å¤„ç†é€»è¾‘ï¼šè‡ªåŠ¨æ›´æ–°æˆå‘˜å˜é‡

        Args:
            handle_name: å¤„ç†å¥æŸ„åç§°
            signal_or_value: Signalå¯¹è±¡æˆ–ç›´æ¥çš„å€¼
            is_direct_value: æ˜¯å¦ä¸ºç›´æ¥å€¼ï¼ˆé€šé…ç¬¦æƒ…å†µï¼‰
        """
        self.logger.debug(
            "Handling default signal processing for handle '%s' with value: %s",
            handle_name,
            signal_or_value,
        )
        if handle_name not in self._input_handles:
            self.logger.debug(
                "Handle '%s' not registered in input handles, skipping auto-update",
                handle_name,
            )
            return

        handle_obj = self._input_handles[handle_name]
        if not handle_obj.auto_update_attr:
            self.logger.debug(
                "Handle '%s' does not have auto_update_attr defined, skipping auto-update",
                handle_name,
            )
            return

        # è·å–è¦æ›´æ–°çš„å€¼
        if is_direct_value:
            raw_value = signal_or_value
        else:
            raw_value = (
                signal_or_value.payload
                if hasattr(signal_or_value, "payload")
                else signal_or_value
            )

        # ç±»å‹æ£€æŸ¥å’Œå€¼æå–
        expected_type = handle_obj.data_type
        final_value = self._extract_typed_value(raw_value, expected_type, handle_name)

        # æ›´æ–°æˆå‘˜å˜é‡
        if hasattr(self, handle_obj.auto_update_attr):
            # å¤„ç†èšåˆç±»å‹å¥æŸ„
            if handle_obj.is_aggregate and handle_obj.data_type == dict:
                # è·å–ä¿¡å·çš„æºå¥æŸ„åç§°ä½œä¸ºkey
                signal_source_handle = getattr(signal_or_value, 'source_handle', None)
                if signal_source_handle:
                    # è·å–å½“å‰èšåˆçŠ¶æ€ï¼Œç¡®ä¿ç±»å‹å®‰å…¨
                    current_value = getattr(self, handle_obj.auto_update_attr)
                    if not isinstance(current_value, dict):
                        current_value = {}

                    # åˆ›å»ºæ–°çš„èšåˆå­—å…¸ï¼ŒåŸºäºå½“å‰æœ€æ–°çŠ¶æ€
                    new_aggregated_value = current_value.copy()

                    # å¦‚æœæ¥æ”¶åˆ°çš„æ˜¯å­—å…¸ï¼Œåˆå¹¶æ‰€æœ‰é”®å€¼
                    if isinstance(final_value, dict):
                        new_aggregated_value.update(final_value)
                        self.logger.debug(
                            "Merged dict signal for aggregate handle '%s': %s",
                            handle_name,
                            final_value,
                        )
                    else:
                        # ä½¿ç”¨æºå¥æŸ„åç§°ä½œä¸ºkey
                        new_aggregated_value[signal_source_handle] = final_value
                        self.logger.debug(
                            "Added simple value to aggregate handle '%s': %s=%s",
                            handle_name,
                            signal_source_handle,
                            final_value,
                        )

                    # æ›´æ–°èšåˆçŠ¶æ€
                    setattr(self, handle_obj.auto_update_attr, new_aggregated_value)
                    self.logger.info(
                        "Auto-updated aggregate %s: %s -> %s (handle: %s, source: %s)",
                        handle_obj.auto_update_attr,
                        current_value,
                        new_aggregated_value,
                        handle_name,
                        signal_source_handle,
                    )
                else:
                    self.logger.warning(
                        "No source_handle found for aggregate signal on handle '%s'",
                        handle_name,
                    )
            else:
                # éèšåˆç±»å‹ï¼Œç›´æ¥æ›¿æ¢
                old_value = getattr(self, handle_obj.auto_update_attr)
                setattr(self, handle_obj.auto_update_attr, final_value)
                self.logger.info(
                    "Auto-updated %s: %s -> %s (handle: %s, type: %s)",
                    handle_obj.auto_update_attr,
                    old_value,
                    final_value,
                    handle_name,
                    expected_type.__name__,
                )
        else:
            self.logger.warning(
                "Auto-update attribute '%s' not found in node (handle: %s)",
                handle_obj.auto_update_attr,
                handle_name,
            )

    def _extract_typed_value(
        self, raw_value: Any, expected_type: type, handle_name: str
    ) -> Any:
        """
        æ ¹æ®æœŸæœ›ç±»å‹ä»åŸå§‹å€¼ä¸­æå–åˆé€‚çš„å€¼

        Args:
            raw_value: åŸå§‹æ¥æ”¶åˆ°çš„å€¼
            expected_type: æœŸæœ›çš„æ•°æ®ç±»å‹
            handle_name: å¥æŸ„åç§°

        Returns:
            Any: æå–å¹¶è½¬æ¢åçš„å€¼
        """
        # å¦‚æœåŸå§‹å€¼å°±æ˜¯æœŸæœ›ç±»å‹ï¼Œç›´æ¥è¿”å›
        if isinstance(raw_value, expected_type):
            return raw_value

        # å®šä¹‰ç®€å•ç±»å‹
        simple_types = (str, int, float, bool)

        # å¦‚æœæœŸæœ›çš„æ˜¯ç®€å•ç±»å‹ï¼Œè€Œæ¥æ”¶åˆ°çš„æ˜¯å­—å…¸
        if expected_type in simple_types and isinstance(raw_value, dict):
            # å°è¯•ä»å­—å…¸ä¸­æå–ä»¥handle_nameä¸ºkeyçš„å€¼
            if handle_name in raw_value:
                extracted_value = raw_value[handle_name]
                self.logger.debug(
                    "Extracted value '%s' from dict for handle '%s'",
                    extracted_value,
                    handle_name,
                )

                # å°è¯•ç±»å‹è½¬æ¢
                try:
                    if expected_type == str:
                        return str(extracted_value)
                    elif expected_type == int:
                        return int(extracted_value)
                    elif expected_type == float:
                        return float(extracted_value)
                    elif expected_type == bool:
                        return bool(extracted_value)
                    else:
                        return extracted_value
                except (ValueError, TypeError) as e:
                    self.logger.warning(
                        "Failed to convert extracted value '%s' to type %s for handle '%s': %s",
                        extracted_value,
                        expected_type.__name__,
                        handle_name,
                        str(e),
                    )
                    return extracted_value
            else:
                self.logger.warning(
                    "Handle '%s' not found in dict payload: %s",
                    handle_name,
                    (
                        list(raw_value.keys())
                        if isinstance(raw_value, dict)
                        else raw_value
                    ),
                )
                return None

        # å¦‚æœæœŸæœ›çš„æ˜¯å¤æ‚ç±»å‹ï¼ˆdict, listç­‰ï¼‰ï¼Œä½†æ¥æ”¶åˆ°ç®€å•ç±»å‹
        elif expected_type not in simple_types and not isinstance(raw_value, dict):
            # æ£€æŸ¥æ˜¯å¦ä¸ºèšåˆå¥æŸ„
            handle_obj = self._input_handles.get(handle_name)
            if handle_obj and handle_obj.is_aggregate and expected_type == dict:
                # å¯¹äºèšåˆç±»å‹çš„dictå¥æŸ„ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                # è¿™é‡Œæˆ‘ä»¬è¿”å›åŸå€¼ï¼Œå®é™…èšåˆé€»è¾‘åœ¨ä¸Šå±‚å¤„ç†
                self.logger.debug(
                    "Handle '%s' is aggregate type, simple value will be aggregated at higher level",
                    handle_name,
                )
                return raw_value
            else:
                self.logger.warning(
                    "Expected complex type %s but received simple type %s for handle '%s'",
                    expected_type.__name__,
                    type(raw_value).__name__,
                    handle_name,
                )
                return raw_value

        # 3. å°è¯•JSONå­—ç¬¦ä¸²è§£æï¼ˆæ–°å¢æ”¯æŒï¼‰
        elif isinstance(raw_value, str) and expected_type in simple_types:
            # é¦–å…ˆå°è¯•JSONè§£æ
            try:
                parsed_json = json.loads(raw_value)
                self.logger.debug(
                    "Successfully parsed JSON string for handle '%s': %s",
                    handle_name,
                    parsed_json,
                )

                # å¦‚æœè§£æå‡ºæ¥æ˜¯å­—å…¸ï¼Œå°è¯•ä»ä¸­æå–å­—æ®µ
                if isinstance(parsed_json, dict):
                    if handle_name in parsed_json:
                        extracted_value = parsed_json[handle_name]
                        self.logger.debug(
                            "Extracted value '%s' from JSON dict for handle '%s'",
                            extracted_value,
                            handle_name,
                        )

                        # å¯¹æå–çš„å€¼è¿›è¡Œç±»å‹è½¬æ¢
                        try:
                            if expected_type == str:
                                return str(extracted_value)
                            elif expected_type == int:
                                return int(extracted_value)
                            elif expected_type == float:
                                return float(extracted_value)
                            elif expected_type == bool:
                                return bool(extracted_value)
                        except (ValueError, TypeError) as e:
                            self.logger.warning(
                                "Failed to convert JSON extracted value '%s' to type %s for handle '%s': %s",
                                extracted_value,
                                expected_type.__name__,
                                handle_name,
                                str(e),
                            )
                            return extracted_value
                    else:
                        self.logger.warning(
                            "Handle '%s' not found in JSON dict payload: %s",
                            handle_name,
                            list(parsed_json.keys()),
                        )

                # å¦‚æœè§£æå‡ºæ¥ç›´æ¥æ˜¯æœŸæœ›çš„ç±»å‹ï¼Œå°è¯•è½¬æ¢
                else:
                    try:
                        if expected_type == str:
                            return str(parsed_json)
                        elif expected_type == int:
                            return int(parsed_json)
                        elif expected_type == float:
                            return float(parsed_json)
                        elif expected_type == bool:
                            return bool(parsed_json)
                    except (ValueError, TypeError) as e:
                        self.logger.warning(
                            "Failed to convert JSON value '%s' to type %s for handle '%s': %s",
                            parsed_json,
                            expected_type.__name__,
                            handle_name,
                            str(e),
                        )
                        return parsed_json

            except json.JSONDecodeError:
                # JSONè§£æå¤±è´¥ï¼Œç»§ç»­å°è¯•ç›´æ¥ç±»å‹è½¬æ¢
                self.logger.debug(
                    "JSON parsing failed for handle '%s', trying direct type conversion",
                    handle_name,
                )
                pass

        # å…¶ä»–æƒ…å†µï¼šå°è¯•ç›´æ¥ç±»å‹è½¬æ¢
        try:
            if expected_type in simple_types:
                if expected_type == str:
                    return str(raw_value)
                elif expected_type == int:
                    return int(raw_value)
                elif expected_type == float:
                    return float(raw_value)
                elif expected_type == bool:
                    return bool(raw_value)

            # å¯¹äºå¤æ‚ç±»å‹ï¼Œç›´æ¥è¿”å›åŸå€¼
            return raw_value

        except (ValueError, TypeError) as e:
            self.logger.warning(
                "Failed to convert value '%s' to type %s for handle '%s': %s",
                raw_value,
                expected_type.__name__,
                handle_name,
                str(e),
            )
            return raw_value

    async def _handle_stop_execution_signal(self, signal: Signal) -> None:
        """
        å¤„ç†åœæ­¢æ‰§è¡Œä¿¡å· - è®¾ç½®åœæ­¢æ ‡è®°è€Œä¸æ˜¯æŠ›å¼‚å¸¸

        Args:
            signal: åœæ­¢æ‰§è¡Œä¿¡å·
        """
        reason = "Unknown reason"
        source_node = "Unknown source"

        if signal.payload:
            reason = signal.payload.get("reason", "Unknown reason")
            source_node = signal.payload.get("source_node", "Unknown source")

        self.logger.warning(
            "Received STOP_EXECUTION signal from %s, reason: %s", source_node, reason
        )

        # è®¾ç½®åœæ­¢æ ‡è®°
        self._stop_execution_requested = True
        self._stop_execution_reason = reason
        self._stop_execution_source = source_node

        # ç«‹å³æ›´æ–°RedisçŠ¶æ€ä¸ºTERMINATED
        await self.set_status(NodeStatus.TERMINATED, f"Stopped by {source_node}: {reason}")

        # å¦‚æœæœ‰ç­‰å¾…ä¸­çš„futureï¼Œå–æ¶ˆå®ƒ
        if self._signal_ready_future and not self._signal_ready_future.done():
            self._signal_ready_future.cancel()
            self.logger.info(
                "Cancelled signal ready future due to stop execution signal"
            )

        # è°ƒç”¨è‡ªå®šä¹‰çš„åœæ­¢å¤„ç†æ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(self, "_on_stop_execution"):
            await self._on_stop_execution(signal)

    async def send_signal(
        self,
        source_handle: str,
        signal_type: SignalType,
        payload: Dict[str, Any] = None,
    ) -> bool:
        """
        Send signal asynchronously

        Args:
            signal_type: Signal type
            payload: Signal data payload

        Returns:
            bool: Whether sending was successful
        """
        try:
            # Send signal
            signal = Signal(
                signal_type=signal_type,
                payload=payload,
                timestamp=None,
            )
            await self.node_signal_publisher.send_signal(source_handle, signal)
            
            # å­˜å‚¨è¾“å‡ºæ•°æ®ï¼Œç”¨äºèŠ‚ç‚¹å®Œæˆæ—¶é€šè¿‡ WebSocket æ¨é€ç»™å‰ç«¯
            self._last_output_data[source_handle] = {
                'signal_type': signal_type.value if hasattr(signal_type, 'value') else str(signal_type),
                'payload': payload or {},
                'timestamp': signal.timestamp,
            }

            # Persist signal data to database for comprehensive status API
            signal_data = {
                source_handle: {
                    'signal_type': signal_type.value if hasattr(signal_type, 'value') else str(signal_type),
                    'payload': payload or {},
                    'timestamp': signal.timestamp
                }
            }

            await self.persist_log(
                message=f"Signal sent from {source_handle}: {signal_type}",
                log_level="INFO",
                log_source="node",
                log_metadata={
                    # ç®€åŒ–å…ƒæ•°æ®ï¼šåªä¿ç•™è·¯ç”±ä¿¡æ¯ï¼Œpayload å­˜åœ¨ Signal è¡¨
                    'event': 'signal_sent',
                    'source_handle': source_handle,
                    'signal_type': str(signal_type)
                }
            )

            # ğŸ”¥ å‘å¸ƒ Signal åˆ° Redisï¼Œä¾›å‰ç«¯å®æ—¶å±•ç¤º
            try:
                # è·å–ç›®æ ‡èŠ‚ç‚¹ä¿¡æ¯
                target_node_ids = []
                for edge in self._output_edges:
                    if edge.source_node_handle == source_handle:
                        target_node_ids.append(edge.target_node)  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ target_node è€Œé target_node_id
                
                # æ¨æ–­æ•°æ®ç±»å‹
                data_type = "unknown"
                if payload is not None:
                    if isinstance(payload, bool):
                        data_type = "boolean"
                    elif isinstance(payload, int):
                        data_type = "integer"
                    elif isinstance(payload, float):
                        data_type = "float"
                    elif isinstance(payload, str):
                        data_type = "string"
                    elif isinstance(payload, list):
                        data_type = "array"
                    elif isinstance(payload, dict):
                        data_type = "object"
                
                publish_result = await publish_signal_async(
                    flow_id=self.flow_id,
                    cycle=self.cycle,
                    source_node_id=self.node_id,
                    source_handle=source_handle,
                    target_node_ids=target_node_ids,
                    signal_type=signal_type.value if hasattr(signal_type, 'value') else str(signal_type),
                    payload=payload,
                    direction="output",  # å‘é€çš„ä¿¡å·æ˜¯ output
                    data_type=data_type,
                )
                
                # æŒä¹…åŒ– Output Signal åˆ°æ•°æ®åº“
                signal_type_str = signal_type.value if hasattr(signal_type, 'value') else str(signal_type)
                if target_node_ids:
                    # ä¸ºæ¯ä¸ªç›®æ ‡èŠ‚ç‚¹åˆ›å»ºè®°å½•
                    for target_node_id in target_node_ids:
                        await persist_signal(
                            flow_id=self.flow_id,
                            cycle=self.cycle,
                            direction="output",
                            from_node_id=self.node_id,
                            to_node_id=target_node_id,
                            source_handle=source_handle,
                            target_handle=None,  # Output ä¿¡å·çš„ target_handle åœ¨æ¥æ”¶æ—¶ç¡®å®š
                            signal_type=signal_type_str,
                            data_type=data_type,
                            payload=payload,
                        )
                else:
                    # å³ä½¿æ²¡æœ‰ç›®æ ‡èŠ‚ç‚¹ï¼Œä¹ŸæŒä¹…åŒ– output ä¿¡å·ï¼ˆç”¨äºè°ƒè¯•å’Œå†å²æŸ¥è¯¢ï¼‰
                    await persist_signal(
                        flow_id=self.flow_id,
                        cycle=self.cycle,
                        direction="output",
                        from_node_id=self.node_id,
                        to_node_id=None,
                        source_handle=source_handle,
                        target_handle=None,
                        signal_type=signal_type_str,
                        data_type=data_type,
                        payload=payload,
                    )
            except Exception as redis_err:
                # Redis å‘å¸ƒ/æŒä¹…åŒ–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                self.logger.warning("Failed to publish/persist signal: %s", str(redis_err))

            return True
        except Exception as e:
            self.logger.error("Failed to send signal: %s", str(e))
            self.logger.error(traceback.format_exc())
            return False

    async def send_stop_execution_signal(
        self, reason: str = "Execution stopped"
    ) -> bool:
        """
        å‘é€åœæ­¢æ‰§è¡Œä¿¡å·

        Args:
            reason: åœæ­¢æ‰§è¡Œçš„åŸå› 

        Returns:
            bool: æ˜¯å¦å‘é€æˆåŠŸ
        """
        try:
            # æ·»åŠ å°å»¶è¿Ÿï¼Œç­‰å¾…ä¸‹æ¸¸èŠ‚ç‚¹åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆè§£å†³race conditionï¼‰
            # ä»æ—¥å¿—çœ‹ä¸‹æ¸¸èŠ‚ç‚¹éœ€è¦çº¦150-400mså®Œæˆé˜Ÿåˆ—ç»‘å®šï¼Œè¿™é‡Œç­‰å¾…1ç§’ç¡®ä¿å®‰å…¨
            await asyncio.sleep(1.0)

            await self.node_signal_publisher.send_stop_execution_signal(reason)

            self.logger.info("Stop execution signal sent successfully, reason: %s", reason)
            return True
        except Exception as e:
            self.logger.error("Failed to send stop execution signal: %s", str(e), exc_info=True)
            return False

    async def _charge_credits_sync(self) -> None:
        """
        åŒæ­¥æ‰£è´¹ - è°ƒç”¨ weather_control HTTP API

        æ ¹æ®èŠ‚ç‚¹ç±»å‹è‡ªåŠ¨åˆ¤æ–­æ‰£è´¹æ ‡å‡†ï¼š
        - code_node: 20 credits
        - æ™®é€š node: 10 credits

        Raises:
            InsufficientCreditsException: ä½™é¢ä¸è¶³æ—¶æŠ›å‡º
        """
        if not self.enable_credits:
            self.logger.debug("Credits tracking is disabled for node %s", self.node_id)
            return

        if not self.user_id:
            self.logger.warning("No user_id provided, skipping credits charge")
            return

        try:
            # åˆ¤æ–­èŠ‚ç‚¹ç±»å‹ï¼šcode_node æˆ–æ™®é€š node
            node_type = self.__class__.__name__.lower()

            # å¦‚æœç±»ååŒ…å« 'code' æˆ–è€… type å±æ€§æ˜¯ 'code_node'ï¼Œåˆ™è§†ä¸º code_node
            is_code_node = 'code' in node_type or getattr(self, 'type', None) == 'code_node'
            credits_cost = 20 if is_code_node else 10

            # è·å– weather_control URL
            weather_control_url = CONFIG.get(
                "WEATHER_CONTROL_URL",
                "http://localhost:8000"
            )

            # è°ƒç”¨åŒæ­¥æ‰£è´¹ API
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.post(
                    f"{weather_control_url}/api/v1/credits/charge",
                    json={
                        "userId": self.user_id,
                        "amount": credits_cost,
                        "nodeId": self.node_id,
                        "nodeType": 'code_node' if is_code_node else 'regular_node',
                        "flowId": self.flow_id,
                        "cycle": self.cycle,
                        "metadata": {
                            "nodeName": self.name,
                            "nodeType": node_type,
                            "componentId": self.component_id,
                        }
                    }
                )

                # æ£€æŸ¥ä½™é¢ä¸è¶³
                if response.status_code == 402:
                    data = response.json()
                    balance = data.get("balance", 0)

                    self.logger.error(
                        f"Insufficient credits: user={self.user_id}, "
                        f"required={credits_cost}, balance={balance}"
                    )

                    raise InsufficientCreditsException(
                        message=f"Insufficient credits to execute node {self.node_id}",
                        node_id=self.node_id,
                        user_id=self.user_id,
                        required_credits=credits_cost,
                        current_balance=balance,
                    )

                # æ£€æŸ¥å…¶ä»–é”™è¯¯
                response.raise_for_status()

                # æ‰£è´¹æˆåŠŸ
                result = response.json()
                remaining_balance = result.get("data", {}).get("balance", 0)

                self.logger.info(
                    f"Credits charged successfully: user={self.user_id}, "
                    f"node={self.node_id}, cost={credits_cost}, "
                    f"remaining={remaining_balance}"
                )

        except InsufficientCreditsException:
            # é‡æ–°æŠ›å‡ºä½™é¢ä¸è¶³å¼‚å¸¸
            raise
        except httpx.TimeoutException as e:
            self.logger.error(f"Timeout charging credits: {str(e)}")
            raise Exception(f"Credits service timeout: {str(e)}")
        except Exception as e:
            self.logger.error(f"Error charging credits: {str(e)}")
            self.logger.error(traceback.format_exc())
            raise Exception(f"Failed to charge credits: {str(e)}")

    def can_execute(self) -> bool:
        """
        Check if node can execute

        Returns:
            bool: True if node can execute
        """
        # If no required signals, can execute immediately
        if not self._input_signals:
            return True

        # Check if all required signals have been received
        for edge_key, signal in self._input_signals.items():
            if signal is None:
                self.logger.debug("Missing required signal for edge: %s", edge_key)
                return False
        return True

    @abc.abstractmethod
    async def execute(self) -> bool:
        """
        Execute node logic, must be overridden by subclasses

        Returns:
            bool: Whether execution was successful
        """

    async def set_status(self, status: NodeStatus, error_message: str = None):
        """
        Set node status and update in state store

        Args:
            status: New status
            error_message: Error message (if any)
        """
        # ğŸ”’ æœ€ç»ˆçŠ¶æ€ä¿æŠ¤ï¼šCOMPLETED, FAILED, TERMINATED æ˜¯æœ€ç»ˆçŠ¶æ€ï¼Œä¸èƒ½è¢«æ”¹å˜
        final_states = {NodeStatus.COMPLETED, NodeStatus.FAILED, NodeStatus.TERMINATED}

        if self.status in final_states:
            self.logger.warning(
                f"Node {self.node_id} is in final state {self.status.value}, "
                f"cannot change to {status.value}. Ignoring status change."
            )
            return

        self.status = status
        self.error_message = error_message

        try:
            if self.state_store:
                # Update node status in state store
                await self.state_store.set_node_task_status(
                    self.node_id, status.value, error_message
                )
        except Exception as e:
            self.logger.error("Failed to update node status in state store: %s", str(e))

        self.logger.info("Node %s status changed to %s", self.node_id, status.value)

        if status == NodeStatus.FAILED and error_message:
            self.logger.error("Node %s failed: %s", self.node_id, error_message)

        # å‘å¸ƒçŠ¶æ€å˜åŒ–åˆ° Redis (å®æ—¶æ¨é€åˆ°å‰ç«¯)
        try:
            from core.redis_status_publisher import publish_node_status

            # æ„å»º metadataï¼ŒåŒ…å«èŠ‚ç‚¹ç±»å‹
            metadata = {
                "node_type": self.node_type,
            }
            
            # å¦‚æœèŠ‚ç‚¹å®Œæˆï¼ŒåŒ…å«è¾“å‡ºæ•°æ®ä¾›å‰ç«¯ä½¿ç”¨
            if status == NodeStatus.COMPLETED and self._last_output_data:
                # æå–ä¸»è¦è¾“å‡ºæ•°æ®ï¼ˆé€šå¸¸æ˜¯ 'data' handleï¼‰
                if 'data' in self._last_output_data:
                    last_output = self._last_output_data['data'].get('payload', {})
                    metadata["lastOutput"] = last_output
                    # ğŸ” è°ƒè¯•ï¼šæ‰“å° lastOutput çš„å¤§å°
                    self.logger.info(
                        "Node %s completed with lastOutput (keys: %s, size: ~%d chars)",
                        self.node_id,
                        list(last_output.keys()) if isinstance(last_output, dict) else type(last_output).__name__,
                        len(str(last_output)[:1000])  # é¿å…æ‰“å°è¿‡å¤§
                    )
                elif self._last_output_data:
                    # å¦‚æœæ²¡æœ‰ 'data' handleï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å‡º
                    first_output = list(self._last_output_data.values())[0]
                    metadata["lastOutput"] = first_output.get('payload', {})
                
                self.logger.info(
                    "Node %s completed with output data (keys: %s)",
                    self.node_id,
                    list(self._last_output_data.keys())
                )

            # ğŸ”¥ æ ¹æ® cycle å€¼æ¨æ–­æ‰§è¡Œç±»å‹ï¼šcycle < 0 è¡¨ç¤º partial run
            execution_type = "partial" if self.cycle < 0 else "global"
            
            publish_node_status(
                flow_id=self.flow_id,
                cycle=self.cycle,
                node_id=self.node_id,
                status=status.value,
                error_message=error_message,
                metadata=metadata,
                execution_type=execution_type,
            )
        except Exception as e:
            # ä¸è®©æ¨é€å¤±è´¥å½±å“èŠ‚ç‚¹æ‰§è¡Œ
            self.logger.debug("Failed to publish status to Redis: %s", str(e))

    # ==================== æš‚åœ/æ¢å¤ç›¸å…³æ–¹æ³• ====================

    async def pause(
        self,
        pause_type: str = "manual",
        resume_context: dict = None,
    ) -> dict:
        """
        æš‚åœå½“å‰èŠ‚ç‚¹æ‰§è¡Œ

        Args:
            pause_type: æš‚åœç±»å‹ ("manual", "error", "breakpoint")
            resume_context: æ¢å¤æ—¶éœ€è¦çš„ä¸Šä¸‹æ–‡æ•°æ®

        Returns:
            æš‚åœçŠ¶æ€æ•°æ®
        """
        from flow.pause_manager import PauseManager, PauseType

        try:
            pause_type_enum = PauseType(pause_type)
        except ValueError:
            pause_type_enum = PauseType.MANUAL

        manager = PauseManager.get_instance()
        await manager.initialize()

        pause_data = await manager.pause_node(
            flow_id=self.flow_id,
            node_id=self.node_id,
            cycle=self.cycle,
            pause_type=pause_type_enum,
            paused_by="node",
            resume_context=resume_context or {},
        )

        self.logger.info(
            "Node %s paused: type=%s", self.node_id, pause_type
        )
        return pause_data

    async def await_input(
        self,
        prompt: str,
        timeout_seconds: int = 300,
        input_options: dict = None,
        resume_context: dict = None,
    ) -> dict:
        """
        æš‚åœèŠ‚ç‚¹ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼ˆæŒä¹…åŒ–æ–¹å¼ï¼‰

        ä¸æ—§çš„ wait_for_response ä¸åŒï¼Œè¿™ä¸ªæ–¹æ³•ï¼š
        1. å°†æš‚åœçŠ¶æ€æŒä¹…åŒ–åˆ° Redis
        2. ä¸åœ¨è¿›ç¨‹å†…é˜»å¡ç­‰å¾…
        3. æ”¯æŒæœåŠ¡é‡å¯åæ¢å¤

        Args:
            prompt: æç¤ºä¿¡æ¯
            timeout_seconds: è¶…æ—¶æ—¶é—´
            input_options: è¾“å…¥é€‰é¡¹ï¼ˆå¦‚ yes/no æ ‡ç­¾ï¼‰
            resume_context: æ¢å¤æ—¶éœ€è¦çš„é¢å¤–ä¸Šä¸‹æ–‡

        Returns:
            æš‚åœçŠ¶æ€æ•°æ®
        """
        from flow.pause_manager import PauseManager, PauseType

        manager = PauseManager.get_instance()
        await manager.initialize()

        input_request = {
            "prompt": prompt,
            "timeout_seconds": timeout_seconds,
            "options": input_options or {},
        }

        pause_data = await manager.pause_node(
            flow_id=self.flow_id,
            node_id=self.node_id,
            cycle=self.cycle,
            pause_type=PauseType.AWAITING_INPUT,
            paused_by="node",
            resume_context=resume_context or {},
            input_request=input_request,
        )

        # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€ä¸ºç­‰å¾…è¾“å…¥
        await self.set_status(NodeStatus.AWAITING_INPUT)

        self.logger.info(
            "Node %s awaiting input: prompt='%s', timeout=%ds",
            self.node_id, prompt[:50], timeout_seconds
        )
        return pause_data

    async def check_paused(self) -> bool:
        """
        æ£€æŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦å¤„äºæš‚åœçŠ¶æ€

        Returns:
            æ˜¯å¦æš‚åœ
        """
        from flow.pause_manager import PauseManager

        manager = PauseManager.get_instance()
        await manager.initialize()

        return await manager.is_node_paused(self.flow_id, self.node_id)

    async def get_resume_context(self) -> dict:
        """
        è·å–æ¢å¤ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœèŠ‚ç‚¹å·²æš‚åœï¼‰

        Returns:
            æ¢å¤ä¸Šä¸‹æ–‡æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æš‚åœåˆ™è¿”å› None
        """
        from flow.pause_manager import PauseManager

        manager = PauseManager.get_instance()
        await manager.initialize()

        pause_state = await manager.get_node_pause_state(self.flow_id, self.node_id)
        if pause_state:
            return pause_state.get("resume_context")
        return None

    async def start(self) -> bool:
        """
        Start node processing.

        If node needs to receive specific signals before executing, wait for all necessary signals;
        If node doesn't depend on any input signals, execute directly.

        Returns:
            bool: Whether execution was successful
        """
        try:
            # Initialize state store
            self.logger.info("Initializing state store")
            if not await self.initialize_state_store():
                self.logger.error("Failed to initialize state store")
                return False

            # Initialize message queue
            self.logger.info("Initializing message queue")
            if not await self.initialize_message_queue():
                self.logger.error("Failed to initialize message queue")
                return False

            # Set node status to running
            await self.set_status(NodeStatus.RUNNING)

            # Decide execution strategy based on whether signals are needed
            if self._input_edges:
                for edge in self._input_edges:
                    await self.persist_log(
                        f"Node {self.node_id} waiting for signal: {edge.source_node_handle} -> {edge.target_node_handle}",
                        log_level="INFO",
                    )
                # Create a new Future
                self._signal_ready_future = asyncio.Future()

                # Start consuming signals
                await self.node_signal_consumer.consume()
                await self.persist_log(
                    f"Node {self.node_id} now listening for signals",
                    log_level="INFO",
                )

                try:
                    # Wait for all required signals
                    await self._signal_ready_future

                    await self.persist_log(
                        f"Node {self.node_id} received all required signals, starting execution",
                        log_level="INFO",
                    )
                    # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä¸è¦åœ¨executeä¹‹å‰å…³é—­consumerï¼Œå¦åˆ™æ”¶ä¸åˆ°STOP_EXECUTIONä¿¡å·
                    # await self.node_signal_consumer.close()

                    # âœ… åœ¨executeä¹‹å‰æ£€æŸ¥åœæ­¢æ ‡å¿—ï¼Œé¿å…ä¸å¿…è¦çš„æ‰§è¡Œ
                    if self._stop_execution_requested:
                        self.logger.warning(
                            f"Node {self.node_id} received stop signal before execution, "
                            f"reason: {self._stop_execution_reason}"
                        )
                        await self.set_status(
                            NodeStatus.TERMINATED,
                            f"Stopped before execution: {self._stop_execution_reason}"
                        )
                        raise NodeStopExecutionException(
                            f"Node execution stopped before start: {self._stop_execution_reason}",
                            node_id=self.node_id,
                            reason=self._stop_execution_reason,
                            source_node=self._stop_execution_source,
                        )

                    # Charge credits BEFORE execution
                    await self._charge_credits_sync()

                    # Execute node logic
                    success = await self.execute()
                    await self.persist_log(
                        f"Node {self.node_id} execution completed, success={success}",
                        log_level="INFO",
                        log_metadata={"success": success},
                    )
                    await self.set_status(
                        NodeStatus.COMPLETED if success else NodeStatus.FAILED
                    )

                    # Forward signals if execution was successful
                    if success:
                        await self._auto_forward_input_handles()
                    else:
                        await self.persist_log(
                            f"Node {self.node_id} execution failed, forwarding input signals skipped",
                            log_level="ERROR",
                            log_metadata={"success": False},
                        )
                        await self.send_stop_execution_signal(
                            reason=f"Node:{self.node_id} execution failed"
                        )
                    return success
                except asyncio.CancelledError:
                    # å¤„ç† Future è¢«å–æ¶ˆçš„æƒ…å†µ
                    await self.persist_log(
                        f"Node {self.node_id} execution was cancelled due to stop signal",
                        log_level="WARNING",
                        log_metadata={"reason": self._stop_execution_reason},
                    )
                    await self.set_status(
                        NodeStatus.TERMINATED, "Execution cancelled by stop signal"
                    )
                    raise NodeStopExecutionException(
                        f"Node execution cancelled: {self._stop_execution_reason}",
                        node_id=self.node_id,
                        reason=self._stop_execution_reason,
                        source_node=self._stop_execution_source,
                    )
                except NodeStopExecutionException:
                    # é‡æ–°æŠ›å‡ºåœæ­¢æ‰§è¡Œå¼‚å¸¸ï¼Œè®© executor å¤„ç†
                    raise

                finally:
                    # ğŸ”¥ åœ¨finallyå—ä¸­å…³é—­consumerï¼Œç¡®ä¿æ— è®ºå¦‚ä½•éƒ½ä¼šæ¸…ç†èµ„æº
                    if self.node_signal_consumer:
                        try:
                            await self.node_signal_consumer.close()
                            self.logger.debug("Node signal consumer closed in finally block")
                        except Exception as e:
                            self.logger.error("Error closing node signal consumer: %s", str(e))
                    # Reset Future
                    self._signal_ready_future = None
            else:
                # No need to wait for signals, execute directly
                await self.persist_log(
                    f"Node {self.node_id} requires no signals, executing directly",
                    log_level="INFO",
                )

                # Charge credits BEFORE execution
                await self._charge_credits_sync()

                success = await self.execute()
                await self.persist_log(
                    f"Node {self.node_id} execution completed, success={success}",
                    log_level="INFO",
                    log_metadata={"success": success},
                )
                await self.set_status(
                    NodeStatus.COMPLETED if success else NodeStatus.FAILED
                )

                # Forward signals if execution was successful
                if success:
                    await self._auto_forward_input_handles()
                else:
                    await self.persist_log(
                        f"Node {self.node_id} execution failed, forwarding input signals skipped",
                        log_level="ERROR",
                        log_metadata={"success": False},
                    )
                    await self.send_stop_execution_signal(
                        reason=f"Node:{self.node_id} execution failed"
                    )
                return success
        except NodeStopExecutionException:
            # é‡æ–°æŠ›å‡ºåœæ­¢æ‰§è¡Œå¼‚å¸¸ï¼Œè®© executor å¤„ç†
            raise

        except Exception as e:
            self.logger.error(
                "Error starting node %s: %s", self.node_id, str(e), exc_info=True
            )
            await self.set_status(NodeStatus.FAILED, str(e))
            return False

    async def cleanup(self):
        """Clean up resources, ensure resource release"""
        try:
            # Close message queue
            await self.node_signal_publisher.close()
            if (
                hasattr(self, "node_signal_consumer")
                and self.node_signal_consumer is not None
            ):
                await self.node_signal_consumer.close()

            # Close state store
            await self.close_state_store()

        except Exception as e:
            self.logger.error("Error during cleanup: %s", str(e))

    async def _auto_forward_input_handles(self) -> None:
        """
        è‡ªåŠ¨è½¬å‘è¾“å…¥ä¿¡å·åˆ°è¾“å‡º

        æ£€æŸ¥output_edgesä¸­çš„source_handleæ˜¯å¦ä¸å½“å‰èŠ‚ç‚¹çš„input_handleåŒ¹é…ï¼Œ
        å¦‚æœåŒ¹é…åˆ™è‡ªåŠ¨å°†æ¥æ”¶åˆ°çš„è¾“å…¥æ•°æ®è½¬å‘ç»™ä¸‹æ¸¸èŠ‚ç‚¹
        """
        self.logger.debug("Auto-forwarding input handles for node %s", self.node_id)

        input_handle_names = self.get_input_handle_names()

        self.logger.debug(
            "Registered input handles for auto-forwarding: %s",
            input_handle_names,
        )
        self.logger.debug(
            "Output edges for auto-forwarding: %s",
            [edge.to_dict() for edge in self._output_edges],
        )

        for output_edge in self._output_edges:
            source_handle = output_edge.source_node_handle

            # æ£€æŸ¥source_handleæ˜¯å¦æ˜¯å½“å‰èŠ‚ç‚¹çš„è¾“å…¥handle
            if source_handle in input_handle_names:
                input_handle_data = self.get_input_handle_data(source_handle)
                await self.send_signal(
                    source_handle=source_handle,
                    signal_type=SignalType.ANY,  # FIXME: ç°åœ¨è·¯ç”±ä¸­æ²¡æœ‰signal_typeäº†ï¼Œå¯ä»¥ä½¿ç”¨é€šç”¨ä¿¡å·ç±»å‹
                    payload=input_handle_data,
                )

                self.logger.info(
                    "Auto-forwarded signal from input handle '%s' to output edge: %s -> %s",
                    source_handle,
                    output_edge.target_node,
                    output_edge.target_node_handle,
                )

    def get_input_handle_data(self, target_handle: str) -> Any:
        """
        æ ¹æ®æ³¨å†Œinput handleè·å–æ•°æ®ï¼ˆè¿çº¿ä¼˜å…ˆï¼‰

        ä¼˜å…ˆçº§ï¼š
        1. å¦‚æœæœ‰è¿æ¥çš„è¾“å…¥ä¿¡å·ï¼ˆ_input_signalsï¼‰ï¼Œä½¿ç”¨ä¿¡å·çš„å€¼
        2. å¦‚æœæ²¡æœ‰è¿æ¥ï¼Œä½¿ç”¨æˆå‘˜å˜é‡çš„å€¼

        Args:
            target_handle: ç›®æ ‡å¥æŸ„åç§°

        Returns:
            Any: å¥æŸ„å¯¹åº”çš„æ•°æ®ï¼Œå¦‚æœå¥æŸ„æœªæ³¨å†Œæˆ–æ²¡æœ‰auto_update_attråˆ™è¿”å›None
        """
        # æ£€æŸ¥å¥æŸ„æ˜¯å¦å·²æ³¨å†Œ
        if target_handle not in self._input_handles:
            self.logger.warning("Input handle '%s' not registered", target_handle)
            return None

        handle_obj = self._input_handles[target_handle]

        # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†auto_update_attr
        if not handle_obj.auto_update_attr:
            self.logger.warning(
                "Input handle '%s' has no auto_update_attr specified", target_handle
            )
            return None

        # ã€è¿çº¿ä¼˜å…ˆé€»è¾‘ã€‘é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰è¿æ¥çš„è¾“å…¥ä¿¡å·
        signal_value = None
        has_signal = False

        for edge_key, signal in self._input_signals.items():
            # edge_key æ ¼å¼: "source_node:source_handle->target_node:target_handle"
            if edge_key.endswith(f"->{target_handle}") or edge_key.endswith(f"->{self.node_id}:{target_handle}"):
                if signal is not None:
                    has_signal = True
                    signal_value = signal.payload
                    self.logger.debug(
                        "Found connected signal for handle '%s' from edge '%s', using signal value (edge priority)",
                        target_handle,
                        edge_key
                    )
                    break

        # å¦‚æœæœ‰è¿æ¥çš„ä¿¡å·ï¼Œä¼˜å…ˆä½¿ç”¨ä¿¡å·çš„å€¼
        if has_signal:
            # èšåˆå¥æŸ„ä¼˜å…ˆè¿”å›èšåˆåçš„æœ€æ–°çŠ¶æ€ï¼Œç¡®ä¿èŠ‚ç‚¹ç«¯èƒ½æ‹¿åˆ°å®Œæ•´æ•°æ®
            if handle_obj.is_aggregate and hasattr(self, handle_obj.auto_update_attr):
                aggregated_value = getattr(self, handle_obj.auto_update_attr)
                if aggregated_value is not None:
                    self.logger.debug(
                        "Using aggregated value for handle '%s' (aggregate handle with edge connected)",
                        target_handle,
                    )
                    return aggregated_value

            self.logger.info(
                "Using signal value for handle '%s' (edge connected, priority over member variable)",
                target_handle
            )
            return signal_value

        # å¦‚æœæ²¡æœ‰è¿æ¥çš„ä¿¡å·ï¼Œä½¿ç”¨æˆå‘˜å˜é‡çš„å€¼
        # æ£€æŸ¥æˆå‘˜å˜é‡æ˜¯å¦å­˜åœ¨
        if not hasattr(self, handle_obj.auto_update_attr):
            self.logger.warning(
                "Attribute '%s' not found in node (handle: %s)",
                handle_obj.auto_update_attr,
                target_handle,
            )
            return None

        # è¿”å›æˆå‘˜å˜é‡çš„å€¼
        value = getattr(self, handle_obj.auto_update_attr)
        self.logger.debug(
            "Retrieved data for handle '%s' from attribute '%s': %s (no edge connected)",
            target_handle,
            handle_obj.auto_update_attr,
            value,
        )
        return value

    def register_input_handle(
        self,
        name: str,
        data_type: type,
        description: str = "",
        example: Any = None,
        auto_update_attr: str = None,
        is_aggregate: bool = False,
    ) -> None:
        """
        Register an input handle

        Args:
            name: Handle name
            data_type: Expected data type
            description: Description of the handle
            example: Example value
            auto_update_attr: Name of the member variable to auto-update when signal is received
            is_aggregate: Whether this handle aggregates signals from multiple sources
        """
        self._input_handles[name] = InputHandle(
            name=name,
            data_type=data_type,
            description=description,
            example=example,
            auto_update_attr=auto_update_attr,
            is_aggregate=is_aggregate,
        )
        self.logger.debug(
            "Registered input handle: %s (%s), aggregate: %s, auto_update_attr: %s",
            name,
            data_type.__name__,
            is_aggregate,
            auto_update_attr,
        )

    def _register_input_handles(self) -> None:
        """
        Register input handles. Should be overridden by subclasses.
        This method is called during initialization.
        """
        # Default implementation does nothing
        # Subclasses should override this method to register their input handles

    def get_input_handles(self) -> Dict[str, InputHandle]:
        """
        Get all registered input handles

        Returns:
            Dict mapping handle names to InputHandle objects
        """
        return self._input_handles.copy()

    def get_input_handle_names(self) -> List[str]:
        """
        Get list of all registered input handle names

        Returns:
            List of handle names
        """
        return list(self._input_handles.keys())

    # ============ Output Handle ç›¸å…³æ–¹æ³• ============

    def register_output_handle(
        self,
        name: str,
        data_type: type,
        description: str = "",
        example: Any = None,
    ) -> None:
        """
        Register an output handle

        Args:
            name: Handle name
            data_type: Output data type
            description: Description of the handle
            example: Example value
        """
        self._output_handles[name] = OutputHandle(
            name=name,
            data_type=data_type,
            description=description,
            example=example,
        )
        self.logger.debug(
            "Registered output handle: %s (%s)",
            name,
            data_type.__name__,
        )

    def _register_output_handles(self) -> None:
        """
        Register output handles. Should be overridden by subclasses.
        This method is called during initialization.
        """
        # Default implementation does nothing
        # Subclasses should override this method to register their output handles

    def get_output_handles(self) -> Dict[str, "OutputHandle"]:
        """
        Get all registered output handles

        Returns:
            Dict mapping handle names to OutputHandle objects
        """
        return self._output_handles.copy()

    def get_output_handle_names(self) -> List[str]:
        """
        Get list of all registered output handle names

        Returns:
            List of handle names
        """
        return list(self._output_handles.keys())

    # ============ å…ƒæ•°æ®ç›¸å…³æ–¹æ³• ============

    def get_metadata(self) -> NodeMetadata:
        """
        Get node metadata (instance-level)

        Returns:
            NodeMetadata: Node metadata object
        """
        return self._instance_metadata

    @classmethod
    def get_class_metadata(cls) -> Optional[NodeMetadata]:
        """
        Get class-level metadata

        Returns:
            Optional[NodeMetadata]: Class metadata if set, None otherwise
        """
        return cls._metadata

    @classmethod
    def set_class_metadata(cls, metadata: NodeMetadata) -> None:
        """
        Set class-level metadata

        Args:
            metadata: NodeMetadata object to set
        """
        cls._metadata = metadata

    def update_metadata(self, **kwargs) -> None:
        """
        Update instance metadata

        Args:
            **kwargs: Metadata fields to update
        """
        for key, value in kwargs.items():
            if hasattr(self._instance_metadata, key):
                setattr(self._instance_metadata, key, value)
            else:
                self.logger.warning(f"Unknown metadata field: {key}")

    def get_version(self) -> str:
        """
        Get node version

        Returns:
            str: Node version
        """
        return self._instance_metadata.version

    def get_display_name(self) -> str:
        """
        Get node display name

        Returns:
            str: Node display name
        """
        return self._instance_metadata.display_name

    def get_node_category(self) -> str:
        """
        Get node category

        Returns:
            str: Node category (base/instance/variant)
        """
        return self._instance_metadata.node_category

    def is_base_node(self) -> bool:
        """
        Check if this is a base node

        Returns:
            bool: True if this is a base node
        """
        return self._instance_metadata.node_category == "base"

    def is_instance_node(self) -> bool:
        """
        Check if this is an instance node

        Returns:
            bool: True if this is an instance node
        """
        return self._instance_metadata.node_category == "instance"

    def get_base_node_type(self) -> Optional[str]:
        """
        Get base node type (for instance nodes)

        Returns:
            Optional[str]: Base node type if this is an instance node
        """
        return self._instance_metadata.base_node_type
