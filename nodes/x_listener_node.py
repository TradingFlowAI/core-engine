import asyncio
# Removed logging import - using persist_log from NodeBase
import re
import traceback
import time
import os
from typing import Any, Dict, List, Optional, Tuple, Union

import requests
from common.edge import Edge
from weather_depot.config import CONFIG

from common.node_decorators import register_node_type
from common.signal_types import SignalType
from nodes.node_base import NodeBase, NodeStatus

# å®šä¹‰è¾“å…¥è¾“å‡ºå¤„ç†å™¨åç§°
# è¾“å…¥å¥æŸ„
# ğŸ”¥ ä¿®å¤ï¼šæ”¹ä¸º accounts (å¤æ•°)ï¼ŒåŒ¹é…å‰ç«¯å’Œ Linter
ACCOUNT_INPUT_HANDLE = "accounts"  # Xè´¦å·è¾“å…¥
KEYWORDS_INPUT_HANDLE = "keywords"  # å…³é”®è¯è¾“å…¥

# è¾“å‡ºå¥æŸ„
LATEST_TWEETS_OUTPUT_HANDLE = "latest_tweets"  # æœ€æ–°æ¨æ–‡è¾“å‡º


def is_user_id(identifier: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸º Twitter user IDï¼ˆçº¯æ•°å­—ï¼‰"""
    return re.fullmatch(r"\d+", identifier) is not None


@register_node_type(
    "x_listener_node",
    default_params={
        "accounts": [],  # Xè´¦å·åˆ—è¡¨ï¼Œæ”¯æŒUserIdå’ŒUserName
        "limit": 20,  # è·å–çš„æ¨æ–‡æ•°é‡é™åˆ¶
        "keywords": "",  # å…³é”®è¯è¿‡æ»¤ï¼Œå¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”
        "search_mode": "user_tweets",  # æœç´¢æ¨¡å¼: "user_tweets" æˆ– "advanced_search"
        "query_type": "Latest",  # æœç´¢ç±»å‹: "Latest" æˆ– "Top"
        "api_key": "",  # Twitter APIå¯†é’¥
    },
)
class XListenerNode(NodeBase):
    """
    Twitterç›‘å¬å™¨èŠ‚ç‚¹ - ç”¨äºè·å–æŒ‡å®šç”¨æˆ·çš„æœ€è¿‘æ¨æ–‡æˆ–è¿›è¡Œé«˜çº§æœç´¢

    è¾“å…¥å‚æ•°:
    - accounts: X çš„ç”¨æˆ·åæˆ–idåˆ—è¡¨ï¼ˆç”¨æˆ·æ¨æ–‡æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
    - keywords: å…³é”®è¯è¿‡æ»¤ï¼Œå¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”
    - search_mode: æœç´¢æ¨¡å¼ ("user_tweets" æˆ– "advanced_search")
    - query_type: æœç´¢ç±»å‹ ("Latest" æˆ– "Top")
    - limit: è·å–çš„æ¨æ–‡æ•°é‡é™åˆ¶
    - api_key: Twitter APIå¯†é’¥

    è¾“å‡ºä¿¡å·:
    - latest_tweets: è·å–çš„æœ€æ–°æ¨æ–‡æ•°æ®
    """

    def __init__(
            self,
            flow_id: str,
            component_id: int,
            cycle: int,
            node_id: str,
            name: str,
            accounts: List[str] = None,
            limit: int = 20,
            keywords: str = "",
            search_mode: str = "user_tweets",
            query_type: str = "Latest",
            api_key: str = "",
            input_edges: List[Edge] = None,
            output_edges: List[Edge] = None,
            state_store=None,
            **kwargs,
    ):
        """
        åˆå§‹åŒ– X ç›‘å¬å™¨èŠ‚ç‚¹

        Args:
            flow_id: æµç¨‹ID
            component_id: ç»„ä»¶ID
            cycle: èŠ‚ç‚¹æ‰§è¡Œå‘¨æœŸ
            node_id: èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†ç¬¦
            name: èŠ‚ç‚¹åç§°
            account: Xç”¨æˆ·å
            tweet_limit: è·å–çš„æ¨æ–‡æ•°é‡é™åˆ¶
            include_user_info: æ˜¯å¦åŒ…å«ç”¨æˆ·ä¿¡æ¯
            api_key: Twitter APIå¯†é’¥
            input_edges: è¾“å…¥è¾¹åˆ—è¡¨
            output_edges: è¾“å‡ºè¾¹åˆ—è¡¨
            state_store: çŠ¶æ€å­˜å‚¨
            **kwargs: ä¼ é€’ç»™åŸºç±»çš„å…¶ä»–å‚æ•°
        """
        super().__init__(
            flow_id=flow_id,
            component_id=component_id,
            cycle=cycle,
            node_id=node_id,
            name=name,
            input_edges=input_edges,
            output_edges=output_edges,
            state_store=state_store,
            **kwargs,
        )

        # ä¿å­˜å‚æ•°
        self.accounts = accounts or []
        self.keywords = keywords.strip() if keywords else ""
        self.search_mode = search_mode
        self.query_type = query_type
        self.limit = max(1, min(100, limit))  # é™åˆ¶åœ¨1-100ä¹‹é—´
        self.api_key = api_key or os.environ.get("TWITTER_API_KEY") or CONFIG.get("TWITTER_API_KEY", "")

        # APIç›¸å…³
        self.user_tweets_url = "https://api.twitterapi.io/twitter/user/last_tweets"
        self.advanced_search_url = "https://api.twitterapi.io/twitter/tweet/advanced_search"
        self.headers = {"X-API-Key": self.api_key}

        # Logger removed - using persist_log from NodeBase

    def _register_input_handles(self) -> None:
        """æ³¨å†Œè¾“å…¥å¥æŸ„"""
        self.register_input_handle(
            name=ACCOUNT_INPUT_HANDLE,
            data_type=str,
            description="Accounts - X çš„ç”¨æˆ·åæˆ–idï¼Œæ”¯æŒuserIdå’ŒuserName",
            example="elonmusk",
            auto_update_attr="accounts",  # ğŸ”¥ ä¿®å¤ï¼šæ”¹ä¸º accounts (å¤æ•°)
        )
        self.register_input_handle(
            name=KEYWORDS_INPUT_HANDLE,
            data_type=str,
            description="Keywords - å…³é”®è¯è¿‡æ»¤ï¼Œå¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”",
            example="AI, Tesla, SpaceX",
            auto_update_attr="keywords",
        )
    
    def _register_output_handles(self) -> None:
        """Register output handles"""
        self.register_output_handle(
            name=LATEST_TWEETS_OUTPUT_HANDLE,
            data_type=list,
            description="Latest Tweets - Twitter/X tweets data",
            example=[{"text": "Tweet content", "author": "@username", "timestamp": "2024-01-01"}],
        )

    async def _build_search_query(self) -> str:
        """
        Build advanced search query string

        Returns:
            str: Search query string
        """
        query_parts = []

        # å¤„ç†å…³é”®è¯
        if self.keywords:
            keywords_list = [kw.strip() for kw in self.keywords.split(',') if kw.strip()]
            if keywords_list:
                # å¦‚æœæœ‰å¤šä¸ªå…³é”®è¯ï¼Œä½¿ç”¨ OR è¿æ¥
                if len(keywords_list) > 1:
                    keywords_query = ' OR '.join([f'"{kw}"' for kw in keywords_list])
                    query_parts.append(f'({keywords_query})')
                else:
                    query_parts.append(f'"{keywords_list[0]}"')

        # å¦‚æœæŒ‡å®šäº†ç”¨æˆ·ï¼Œæ·»åŠ  from: æ“ä½œç¬¦
        if self.account and self.search_mode == "advanced_search":
            if is_user_id(self.account):
                # å¦‚æœæ˜¯ç”¨æˆ·IDï¼Œéœ€è¦è½¬æ¢ä¸ºç”¨æˆ·åæˆ–ä½¿ç”¨å…¶ä»–æ–¹å¼
                await self.persist_log(f"Advanced search does not support user ID, skipping user filter: {self.account}", "WARNING")
            else:
                query_parts.append(f"from:{self.account}")

        # å¦‚æœæ²¡æœ‰ä»»ä½•æŸ¥è¯¢æ¡ä»¶ï¼Œè¿”å›é»˜è®¤æŸ¥è¯¢
        if not query_parts:
            return "twitter"  # é»˜è®¤æœç´¢

        return ' '.join(query_parts)

    async def _filter_tweets_by_keywords(self, tweets: List[Dict]) -> List[Dict]:
        """
        Filter tweets by keywords

        Args:
            tweets: List of tweets

        Returns:
            List[Dict]: Filtered list of tweets
        """
        if not self.keywords or not tweets:
            return tweets

        keywords_list = [kw.strip().lower() for kw in self.keywords.split(',') if kw.strip()]
        if not keywords_list:
            return tweets

        filtered_tweets = []
        for tweet in tweets:
            tweet_text = tweet.get('text', '').lower()
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•å…³é”®è¯
            if any(keyword in tweet_text for keyword in keywords_list):
                filtered_tweets.append(tweet)

        await self.persist_log(f"Keyword filtering: {len(tweets)} -> {len(filtered_tweets)} tweets", "INFO")
        return filtered_tweets

    async def fetch_tweets_advanced_search(self, cursor="", max_pages=5) -> Dict[str, Any]:
        """
        ä½¿ç”¨é«˜çº§æœç´¢APIè·å–æ¨æ–‡

        Args:
            cursor: åˆ†é¡µæ¸¸æ ‡
            max_pages: æœ€å¤§é¡µæ•°

        Returns:
            Dict[str, Any]: åŒ…å«æ¨æ–‡å’Œç”¨æˆ·ä¿¡æ¯çš„å­—å…¸
        """
        query = await self._build_search_query()
        await self.persist_log(f"Using advanced search query: {query}", "INFO")

        all_tweets = []
        current_page = 0
        current_cursor = cursor

        try:
            while current_page < max_pages:
                # æ„å»ºæŸ¥è¯¢å‚æ•°
                params = {
                    "query": query,
                    "queryType": self.query_type
                }

                if current_cursor:
                    params["cursor"] = current_cursor

                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥APIè°ƒç”¨
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(
                    None,
                    lambda: requests.get(self.advanced_search_url, headers=self.headers, params=params)
                )

                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code != 200:
                    error_msg = f"Advanced search API request failed: {response.status_code} - {response.text}"
                    await self.persist_log(error_msg, "ERROR")
                    return {"error": error_msg, "tweets": all_tweets}

                # è§£æå“åº”
                response_data = response.json()

                # è·å–æ¨æ–‡
                tweets = response_data.get("tweets", [])
                all_tweets.extend(tweets)

                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šé¡µ
                has_next_page = response_data.get("has_next_page", False)
                if not has_next_page or len(all_tweets) >= self.limit:
                    break

                # æ›´æ–°æ¸¸æ ‡å’Œé¡µæ•°
                current_cursor = response_data.get("next_cursor", "")
                current_page += 1

                # å¦‚æœæ²¡æœ‰ä¸‹ä¸€é¡µçš„æ¸¸æ ‡ï¼Œé€€å‡ºå¾ªç¯
                if not current_cursor:
                    break

                # ç®€å•çš„é€Ÿç‡é™åˆ¶
                await asyncio.sleep(0.5)

            # é™åˆ¶è¿”å›çš„æ¨æ–‡æ•°é‡
            if len(all_tweets) > self.limit:
                all_tweets = all_tweets[:self.limit]

            return {
                "tweets": all_tweets,
                "total_count": len(all_tweets),
                "next_cursor": current_cursor if current_page < max_pages else ""
            }

        except Exception as e:
            error_msg = f"Advanced search execution error: {str(e)}"
            await self.persist_log(error_msg, "ERROR")
            await self.persist_log(traceback.format_exc(), "DEBUG")
            return {"error": error_msg, "tweets": all_tweets}

    async def fetch_tweets_for_account(self, account: str, cursor="", max_pages=5) -> Dict[str, Any]:
        """
        è·å–å•ä¸ªç”¨æˆ·çš„æœ€è¿‘æ¨æ–‡

        Args:
            account: Twitterç”¨æˆ·åæˆ–ID
            cursor: åˆ†é¡µæ¸¸æ ‡
            max_pages: æœ€å¤§é¡µæ•°

        Returns:
            Dict[str, Any]: åŒ…å«æ¨æ–‡å’Œç”¨æˆ·ä¿¡æ¯çš„å­—å…¸
        """
        if not account:
            error_msg = "Account parameter is required"
            await self.persist_log(error_msg, "ERROR")
            return {"error": error_msg, "tweets": []}

        if is_user_id(account):
            user_id = account
            user_name = None
        else:
            user_name = account
            user_id = None

        # å‡†å¤‡ç»“æœå®¹å™¨
        all_tweets = []
        user_info = None
        current_page = 0
        current_cursor = cursor

        try:
            while current_page < max_pages:
                # æ„å»ºæŸ¥è¯¢å‚æ•°
                params = {}
                if user_id:
                    params["userId"] = user_id
                else:
                    params["userName"] = user_name

                if current_cursor:
                    params["cursor"] = current_cursor

                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥APIè°ƒç”¨
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(
                    None,
                    lambda: requests.get(self.user_tweets_url, headers=self.headers, params=params)
                )

                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code != 200:
                    error_msg = f"API request failed: {response.status_code} - {response.text}"
                    await self.persist_log(error_msg, "ERROR")
                    return {"error": error_msg, "tweets": all_tweets, "user_info": user_info}

                # è§£æå“åº”
                response_data = response.json()
                if response_data.get("status") != "success":
                    error_msg = f"API returned error: {response_data.get('msg') or response_data.get('message')}"
                    await self.persist_log(error_msg, "ERROR")
                    return {"error": error_msg, "tweets": all_tweets, "user_info": user_info}

                # è·å–æ¨æ–‡ - é€‚åº”æ–°çš„APIå“åº”ç»“æ„
                data = response_data.get("data", {})
                tweets = data.get("tweets", [])

                # Filter tweets by keywords
                if self.keywords:
                    tweets = await self._filter_tweets_by_keywords(tweets)

                all_tweets.extend(tweets)

                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šé¡µ - é€‚åº”æ–°çš„APIå“åº”ç»“æ„
                has_next_page = response_data.get("has_next_page", False)
                if not has_next_page or len(all_tweets) >= self.limit:
                    break

                # æ›´æ–°æ¸¸æ ‡å’Œé¡µæ•° - é€‚åº”æ–°çš„APIå“åº”ç»“æ„
                current_cursor = response_data.get("next_cursor", "")
                current_page += 1

                # å¦‚æœæ²¡æœ‰ä¸‹ä¸€é¡µçš„æ¸¸æ ‡ï¼Œé€€å‡ºå¾ªç¯
                if not current_cursor:
                    break

                # ç®€å•çš„é€Ÿç‡é™åˆ¶
                await asyncio.sleep(0.5)

            # é™åˆ¶è¿”å›çš„æ¨æ–‡æ•°é‡
            if len(all_tweets) > self.limit:
                all_tweets = all_tweets[:self.limit]

            return {
                "tweets": all_tweets,
                "user_info": user_info,
                "total_count": len(all_tweets),
                "next_cursor": current_cursor if current_page < max_pages else ""
            }

        except Exception as e:
            error_msg = f"Error fetching tweets: {str(e)}"
            await self.persist_log(error_msg, "ERROR")
            await self.persist_log(traceback.format_exc(), "DEBUG")
            return {"error": error_msg, "tweets": all_tweets, "user_info": user_info}

    async def fetch_tweets_for_all_accounts(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰è´¦æˆ·çš„æ¨æ–‡

        Returns:
            Dict[str, Any]: åŒ…å«æ‰€æœ‰æ¨æ–‡çš„å­—å…¸
        """
        all_tweets = []
        all_errors = []
        
        await self.persist_log(f"Starting to fetch tweets from {len(self.accounts)} accounts", "INFO")
        
        for account in self.accounts:
            await self.persist_log(f"Fetching tweets from account: {account}", "INFO")
            
            # ä¸ºæ¯ä¸ªè´¦æˆ·è·å–æ¨æ–‡
            account_result = await self.fetch_tweets_for_account(account)
            
            if "error" in account_result:
                error_msg = f"Failed to fetch from account {account}: {account_result['error']}"
                await self.persist_log(error_msg, "WARNING")
                all_errors.append(error_msg)
            else:
                tweets = account_result.get("tweets", [])
                # ä¸ºæ¯æ¡æ¨æ–‡æ·»åŠ æ¥æºè´¦æˆ·ä¿¡æ¯
                for tweet in tweets:
                    tweet["source_account"] = account
                
                all_tweets.extend(tweets)
                await self.persist_log(f"Fetched {len(tweets)} tweets from account {account}", "INFO")
            
            # ç®€å•çš„é€Ÿç‡é™åˆ¶ï¼Œé¿å…APIè°ƒç”¨è¿‡å¿«
            await asyncio.sleep(0.5)
        
        # æŒ‰æ—¶é—´æ’åºæ‰€æœ‰æ¨æ–‡ï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ï¼‰
        try:
            all_tweets.sort(key=lambda x: x.get('created_at', ''), reverse=True)
        except:
            pass  # å¦‚æœæ’åºå¤±è´¥ï¼Œä¿æŒåŸé¡ºåº
        
        # é™åˆ¶æ€»æ¨æ–‡æ•°é‡
        if len(all_tweets) > self.limit:
            all_tweets = all_tweets[:self.limit]
        
        await self.persist_log(f"Total fetched {len(all_tweets)} tweets", "INFO")
        
        result = {
            "tweets": all_tweets,
            "total_count": len(all_tweets),
            "accounts_processed": len(self.accounts),
            "errors": all_errors
        }
        
        # å¦‚æœæ‰€æœ‰è´¦æˆ·éƒ½å¤±è´¥äº†ï¼Œè¿”å›é”™è¯¯
        if len(all_errors) == len(self.accounts) and len(all_tweets) == 0:
            result["error"] = f"All accounts failed to fetch: {'; '.join(all_errors)}"
        
        return result

    async def execute(self) -> bool:
        """æ‰§è¡ŒèŠ‚ç‚¹é€»è¾‘ï¼Œè·å–Twitterç”¨æˆ·çš„æœ€è¿‘æ¨æ–‡æˆ–è¿›è¡Œé«˜çº§æœç´¢"""
        start_time = time.time()
        try:
            mode_desc = "advanced search" if self.search_mode == "advanced_search" else f"tweets from users {', '.join(self.accounts)}"
            await self.persist_log(f"Executing XListenerNode, mode: {self.search_mode}, fetching {mode_desc}", "INFO")

            # æ£€æŸ¥APIå¯†é’¥
            if not self.api_key:
                error_msg = "Twitter API key not provided"
                await self.persist_log(error_msg, "ERROR")
                await self.set_status(NodeStatus.FAILED, error_msg)
                return False

            # æ ¹æ®æœç´¢æ¨¡å¼æ£€æŸ¥å‚æ•°
            if self.search_mode == "user_tweets":
                if not self.accounts:
                    error_msg = "Accounts parameter is required when fetching user tweets"
                    await self.persist_log(error_msg, "ERROR")
                    await self.set_status(NodeStatus.FAILED, error_msg)
                    return False
            elif self.search_mode == "advanced_search":
                if not self.keywords and not self.accounts:
                    error_msg = "Keywords or accounts parameter is required for advanced search"
                    await self.persist_log(error_msg, "ERROR")
                    await self.set_status(NodeStatus.FAILED, error_msg)
                    return False

            await self.set_status(NodeStatus.RUNNING)

            # æ ¹æ®æœç´¢æ¨¡å¼è·å–æ¨æ–‡
            if self.search_mode == "advanced_search":
                result = await self.fetch_tweets_advanced_search()
            else:
                result = await self.fetch_tweets_for_all_accounts()

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if "error" in result:
                error_msg = result["error"]
                await self.persist_log(error_msg, "ERROR")
                await self.set_status(NodeStatus.FAILED, error_msg)
                return False

            # å‘é€æ¨æ–‡æ•°æ®
            tweets_data = {
                "tweets": result["tweets"],
                "count": len(result["tweets"]),
                "accounts": self.accounts,
                "keywords": self.keywords,
                "search_mode": self.search_mode,
                "query_type": self.query_type,
                "timestamp": time.time(),
                "next_cursor": result.get("next_cursor", "")
            }

            if await self.send_signal(LATEST_TWEETS_OUTPUT_HANDLE, SignalType.DATASET, payload=tweets_data):
                await self.persist_log(f"Successfully sent {len(result['tweets'])} tweet data records", "INFO")
            else:
                await self.persist_log("Failed to send tweet data", "WARNING")

            # Set completion status
            execution_time = time.time() - start_time
            await self.persist_log(f"XListenerNode execution completed, time taken: {execution_time:.2f} seconds", "INFO")
            await self.set_status(NodeStatus.COMPLETED)
            return True

        except asyncio.CancelledError:
            # Task was cancelled
            await self.set_status(NodeStatus.TERMINATED, "Task was cancelled")
            return True
        except Exception as e:
            error_msg = f"XListenerNode execution error: {str(e)}"
            await self.persist_log(error_msg, "ERROR")
            await self.persist_log(traceback.format_exc(), "DEBUG")
            await self.set_status(NodeStatus.FAILED, error_msg)
            return False
